{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train and test dasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "train_df = pd.read_csv('train_sessions.csv')\n",
    "test_df = pd.read_csv('test_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data types in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253561 entries, 0 to 253560\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   session_id  253561 non-null  int64  \n",
      " 1   site1       253561 non-null  int64  \n",
      " 2   time1       253561 non-null  object \n",
      " 3   site2       250098 non-null  float64\n",
      " 4   time2       250098 non-null  object \n",
      " 5   site3       246919 non-null  float64\n",
      " 6   time3       246919 non-null  object \n",
      " 7   site4       244321 non-null  float64\n",
      " 8   time4       244321 non-null  object \n",
      " 9   site5       241829 non-null  float64\n",
      " 10  time5       241829 non-null  object \n",
      " 11  site6       239495 non-null  float64\n",
      " 12  time6       239495 non-null  object \n",
      " 13  site7       237297 non-null  float64\n",
      " 14  time7       237297 non-null  object \n",
      " 15  site8       235224 non-null  float64\n",
      " 16  time8       235224 non-null  object \n",
      " 17  site9       233084 non-null  float64\n",
      " 18  time9       233084 non-null  object \n",
      " 19  site10      231052 non-null  float64\n",
      " 20  time10      231052 non-null  object \n",
      " 21  target      253561 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(10)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data types in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82797 entries, 0 to 82796\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   session_id  82797 non-null  int64  \n",
      " 1   site1       82797 non-null  int64  \n",
      " 2   time1       82797 non-null  object \n",
      " 3   site2       81308 non-null  float64\n",
      " 4   time2       81308 non-null  object \n",
      " 5   site3       80075 non-null  float64\n",
      " 6   time3       80075 non-null  object \n",
      " 7   site4       79182 non-null  float64\n",
      " 8   time4       79182 non-null  object \n",
      " 9   site5       78341 non-null  float64\n",
      " 10  time5       78341 non-null  object \n",
      " 11  site6       77566 non-null  float64\n",
      " 12  time6       77566 non-null  object \n",
      " 13  site7       76840 non-null  float64\n",
      " 14  time7       76840 non-null  object \n",
      " 15  site8       76151 non-null  float64\n",
      " 16  time8       76151 non-null  object \n",
      " 17  site9       75484 non-null  float64\n",
      " 18  time9       75484 non-null  object \n",
      " 19  site10      74806 non-null  float64\n",
      " 20  time10      74806 non-null  object \n",
      "dtypes: float64(9), int64(2), object(10)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert time columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_columns = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[time_columns] = train_df[time_columns].fillna(0)\n",
    "test_df[time_columns] = test_df[time_columns].fillna(0)\n",
    "\n",
    "for column in time_columns:\n",
    "    train_df[column] = pd.to_datetime(train_df[column])\n",
    "    test_df[column] = pd.to_datetime(test_df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert site data to bag of words\n",
    "\n",
    "Read site data to temporary txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_columns = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[site_columns].fillna(0).astype(int).to_csv('train_sessions.txt', sep=' ', index=None, header=None)\n",
    "test_df[site_columns].fillna(0).astype(int).to_csv('test_sessions.txt', sep=' ', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data from files to bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 41592), (82797, 41592))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "with open('train_sessions.txt') as inp_train_file:\n",
    "    X_train = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions.txt') as inp_test_file:\n",
    "    X_test = cv.transform(inp_test_file)\n",
    "    \n",
    "X_train.shape, X_test.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert target column of train dataset to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9626805505012536, 0.0017373139537141871)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "lr = LogisticRegression(max_iter=300, C=1, random_state=88)\n",
    "cv = cross_val_score(lr, X_train, y_train, cv=5, n_jobs=7, scoring='roc_auc')\n",
    "np.mean(cv), np.std(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "prediction = lr.predict_proba(X_test)[:,1]\n",
    "prediction = pd.Series(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write prediction to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_to_file(prediction, test_df):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['session_id'] = test_df['session_id'].copy()\n",
    "    submission['target'] = prediction\n",
    "    submission.to_csv('submission.csv', index=None)\n",
    "    \n",
    "write_submission_to_file(prediction, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got a 0.90744 score on Kaggle. Let's impove it by adding time features.\n",
    "\n",
    "# Add new features\n",
    "\n",
    "* hour of session start\n",
    "* part of day: morning, noon, evening, night\n",
    "* number of visited sites (not unique) in session \n",
    "* length of session in seconds\n",
    "* average time of site visit in seconds\n",
    "\n",
    "# Add hour of session start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['start_hour'] = train_df['time1'].dt.hour.astype(int)\n",
    "test_df['start_hour'] = test_df['time1'].dt.hour.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add part of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_part_of_day(value):\n",
    "    if value < 6:\n",
    "        return 1\n",
    "    elif value < 12:\n",
    "        return 2\n",
    "    elif value < 18:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "train_df['part_of_day'] = train_df['start_hour'].apply(determine_part_of_day)\n",
    "test_df['part_of_day'] = test_df['start_hour'].apply(determine_part_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine last visit time for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_time = pd.to_datetime(0)\n",
    "\n",
    "def determine_last_visit_time(row):\n",
    "    last_visit = null_time\n",
    "    for value in row:\n",
    "        if value == null_time:\n",
    "            return last_visit\n",
    "        else:\n",
    "            last_visit = value\n",
    "    return last_visit\n",
    "\n",
    "train_df['last_visit'] = train_df[time_columns].apply(determine_last_visit_time, axis=1)\n",
    "test_df['last_visit'] = test_df[time_columns].apply(determine_last_visit_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add length of session in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['session_length'] = (train_df['last_visit'] - train_df['time1']).dt.total_seconds().astype(int)\n",
    "test_df['session_length'] = (test_df['last_visit'] - test_df['time1']).dt.total_seconds().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add num of visited sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[site_columns] = train_df[site_columns].fillna(0)\n",
    "test_df[site_columns] = test_df[site_columns].fillna(0)\n",
    "\n",
    "train_df['num_of_sites'] = train_df[site_columns].apply(np.count_nonzero, axis=1)\n",
    "test_df['num_of_sites'] = test_df[site_columns].apply(np.count_nonzero, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add average normalized session time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['avg_session_time'] = train_df['session_length']/train_df['num_of_sites']\n",
    "test_df['avg_session_time'] = test_df['session_length']/test_df['num_of_sites']\n",
    "\n",
    "train_df['avg_session_time'] = (train_df['avg_session_time'] - \n",
    "                                train_df['avg_session_time'].min())/train_df['avg_session_time'].max()\n",
    "test_df['avg_session_time'] = (test_df['avg_session_time'] - \n",
    "                               test_df['avg_session_time'].min())/train_df['avg_session_time'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new feature columns to  train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for a best Hyperparameters of Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 64 candidates, totalling 256 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=7)]: Done  47 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=7)]: Done  58 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=7)]: Done  71 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=7)]: Done  84 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=7)]: Done  99 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=7)]: Done 114 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=7)]: Done 131 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=7)]: Done 148 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=7)]: Done 167 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=7)]: Done 207 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=7)]: Done 228 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=7)]: Done 256 out of 256 | elapsed: 20.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'C': 1.0, 'class_weight': None, 'solver': 'saga'}, 0.9617833375130993)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\usr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_opt = LogisticRegression(max_iter=300, random_state=17)\n",
    "solver_list = ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "C_list = np.logspace(-4, 3, 8)\n",
    "class_weight_list = ['balanced', None]\n",
    "param_grid_lr = {'C': C_list, 'solver': solver_list, 'class_weight': class_weight_list}\n",
    "\n",
    "grid_lr = GridSearchCV(lr_opt, param_grid_lr, return_train_score=True, cv=4, n_jobs=7, scoring = 'roc_auc', verbose=10)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "print((grid_lr.best_params_, grid_lr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test target values with Grid Search and write submission to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr.fit(X_train, y_train)\n",
    "grid_lr_prediction = grid_lr.predict_proba(X_test)[:,1]\n",
    "grid_lr_prediction = pd.Series(grid_lr_prediction)\n",
    "\n",
    "write_submission_to_file(grid_lr_prediction, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for a best Hyperparameters of Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=7)]: Done  47 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=7)]: Done  58 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=7)]: Done  71 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=7)]: Done  84 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=7)]: Done  99 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=7)]: Done 114 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=7)]: Done 131 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=7)]: Done 148 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=7)]: Done 167 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=7)]: Done 200 out of 200 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'class_weight': None, 'criterion': 'entropy', 'min_samples_split': 10}, 0.966549918648429)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "criterion_list = ['gini', 'entropy']\n",
    "min_samples_split_list = [2, 4, 6, 8, 10]\n",
    "class_weight_list = ['balanced', {0:1, 1:50}, {0:1, 1:75}, {0:1, 1:100}, None]\n",
    "param_grid_rf = {'criterion': criterion_list, 'min_samples_split': min_samples_split_list, \n",
    "                 'class_weight': class_weight_list}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, return_train_score=True, cv=4, n_jobs=7, scoring = 'roc_auc', verbose=10)\n",
    "grid_rf.fit(X, y)\n",
    "print((grid_rf.best_params_, grid_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Hyperparameter optimization for Random Forest model\n",
    "\n",
    "Increase number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=7)]: Done   2 out of   4 | elapsed:  7.1min remaining:  7.1min\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   4 | elapsed:  7.3min finished\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   4 | elapsed:  7.3min remaining:    0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9764965945993147"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight = None, min_samples_split=10, n_estimators=1000, criterion='entropy', random_state=17)\n",
    "\n",
    "cv = cross_val_score(rf, X, y, scoring='roc_auc', cv=4, n_jobs=7, verbose=10)\n",
    "np.mean(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Grid Search for hyperparameter *n_estimators*=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=7)]: Done  27 out of  36 | elapsed: 41.2min remaining: 13.7min\n",
      "[Parallel(n_jobs=7)]: Done  31 out of  36 | elapsed: 51.2min remaining:  8.3min\n",
      "[Parallel(n_jobs=7)]: Done  36 out of  36 | elapsed: 56.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'class_weight': None, 'min_samples_split': 9}, 0.9771026008513681)\n"
     ]
    }
   ],
   "source": [
    "min_samples_split_list = [9, 10, 11]\n",
    "class_weight_list = ['balanced', None, {0:1, 1:75}]\n",
    "param_grid_rf = {'min_samples_split': min_samples_split_list, 'class_weight': class_weight_list}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, criterion='entropy')\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, return_train_score=True, cv=4, n_jobs=7, scoring = 'roc_auc', verbose=10)\n",
    "grid_rf.fit(X, y)\n",
    "print((grid_rf.best_params_, grid_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test target with optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    251266\n",
       "1      2295\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, class_weight=None, n_jobs=7)\n",
    "rf.fit(X, y)\n",
    "prediction = rf.predict(train[features])\n",
    "submission = pd.DataFrame()\n",
    "submission['session_id'] = train['session_id'].copy()\n",
    "submission['target'] = prediction\n",
    "submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    251264\n",
       "1      2297\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>delta0</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>delta5</th>\n",
       "      <th>delta6</th>\n",
       "      <th>delta7</th>\n",
       "      <th>delta8</th>\n",
       "      <th>delta9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5397</td>\n",
       "      <td>5395</td>\n",
       "      <td>22</td>\n",
       "      <td>5396</td>\n",
       "      <td>5402</td>\n",
       "      <td>5392</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>338</td>\n",
       "      <td>1385126629</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>10941</td>\n",
       "      <td>9783</td>\n",
       "      <td>9786</td>\n",
       "      <td>27339</td>\n",
       "      <td>27338</td>\n",
       "      <td>29</td>\n",
       "      <td>27339</td>\n",
       "      <td>9783</td>\n",
       "      <td>9785</td>\n",
       "      <td>10941</td>\n",
       "      <td>1395682454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>37</td>\n",
       "      <td>270</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>704</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>12623</td>\n",
       "      <td>704</td>\n",
       "      <td>1392295609</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>677</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>678</td>\n",
       "      <td>22</td>\n",
       "      <td>678</td>\n",
       "      <td>1392655323</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>77</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>77</td>\n",
       "      <td>879</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>1379002915</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252789</th>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>879</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>1385729486</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252849</th>\n",
       "      <td>2271</td>\n",
       "      <td>37</td>\n",
       "      <td>17283</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>17283</td>\n",
       "      <td>143</td>\n",
       "      <td>33</td>\n",
       "      <td>18876</td>\n",
       "      <td>1385730150</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253139</th>\n",
       "      <td>4694</td>\n",
       "      <td>27332</td>\n",
       "      <td>2409</td>\n",
       "      <td>27332</td>\n",
       "      <td>2401</td>\n",
       "      <td>27332</td>\n",
       "      <td>27332</td>\n",
       "      <td>4696</td>\n",
       "      <td>27332</td>\n",
       "      <td>2401</td>\n",
       "      <td>1395679970</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253442</th>\n",
       "      <td>22</td>\n",
       "      <td>617</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>879</td>\n",
       "      <td>1440</td>\n",
       "      <td>1307</td>\n",
       "      <td>77</td>\n",
       "      <td>1397496657</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>309</td>\n",
       "      <td>310</td>\n",
       "      <td>310</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253445</th>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>879</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>80</td>\n",
       "      <td>879</td>\n",
       "      <td>1379007110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2297 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "152      5397   5395     22   5396   5402   5392     22     35     33     338   \n",
       "286     10941   9783   9786  27339  27338     29  27339   9783   9785   10941   \n",
       "429        37    270     32     33     35    704     29     33  12623     704   \n",
       "643        39     23    677     22     39     23     21    678     22     678   \n",
       "681        77    879     80    879     80    879     77    879    879      80   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "252789     80    879    879    879     80     80     76     80     80      80   \n",
       "252849   2271     37  17283     29     29     30  17283    143     33   18876   \n",
       "253139   4694  27332   2409  27332   2401  27332  27332   4696  27332    2401   \n",
       "253442     22    617     76     80     76     82    879   1440   1307      77   \n",
       "253445     80     77     80    879    879    879     80    879     80     879   \n",
       "\n",
       "            delta0  delta1  delta2  delta3  delta4  delta5  delta6  delta7  \\\n",
       "152     1385126629       0       1       1       1       1       2       5   \n",
       "286     1395682454       0       0       0       1       1       1       1   \n",
       "429     1392295609      85      88      89      89      94      96     119   \n",
       "643     1392655323       3       5       9       9       9       9      10   \n",
       "681     1379002915       1       3       3       9      11      15      18   \n",
       "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "252789  1385729486       6      10      21      30      39      59      61   \n",
       "252849  1385730150      28      50      50      51      51      51      51   \n",
       "253139  1395679970       2       2       3       3       4       5       7   \n",
       "253442  1397496657       0     305     309     310     310     311     311   \n",
       "253445  1379007110       1       1       2       5       9      10      18   \n",
       "\n",
       "        delta8  delta9  \n",
       "152          5       5  \n",
       "286          1       1  \n",
       "429        119     119  \n",
       "643         12      14  \n",
       "681         19      19  \n",
       "...        ...     ...  \n",
       "252789      79      87  \n",
       "252849      51      51  \n",
       "253139       7       9  \n",
       "253442     312     312  \n",
       "253445      20      24  \n",
       "\n",
       "[2297 rows x 20 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['target'] == 1, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit = Pipeline([('scaler', StandardScaler()), ('logit', LogisticRegression(max_iter=100, C=0.1, \n",
    "                                                                                  class_weight='ba', \n",
    "                                                                                  solver='saga', n_jobs=7))])\n",
    "pipe_logit.fit(X, y)\n",
    "prediction = pipe_logit.predict(test[features])\n",
    "submission = pd.DataFrame()\n",
    "submission['session_id'] = test['session_id'].copy()\n",
    "submission['target'] = prediction\n",
    "submission['target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
